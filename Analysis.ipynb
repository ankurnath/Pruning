{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections  import defaultdict\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def load_from_pickle(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a pickle file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: The path to the pickle file.\n",
    "\n",
    "    Returns:\n",
    "    - loaded_data: The loaded data.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        loaded_data = pickle.load(file)\n",
    "    print(f'Data has been loaded from {file_path}')\n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for problem in [\n",
    "                # 'MaxCover',\n",
    "                'MaxCut',\n",
    "                # 'IM'\n",
    "              ]:\n",
    "    root_folder=os.path.join(problem,'data')\n",
    "    # datasets=['Facebook','DBLP','Skitter','YouTube']\n",
    "    \n",
    "    datasets=os.listdir(root_folder)\n",
    "    print(datasets)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        print('*'*20)\n",
    "        print(dataset)\n",
    "        dataset_path = os.path.join(root_folder,dataset)\n",
    "        algorthims = os.listdir(dataset_path)\n",
    "\n",
    "        # df ={'algorithm':[],'Size of Ground Set':[],'Ratio':[],'Queries':[]}\n",
    "        df = defaultdict(list)\n",
    "        # for algorthim in ['Quickfilter','SS','LeNSE','CombHelperTeacher','CombHelperStudent','GNNpruner']:\n",
    "        for algorthim in ['Quickfilter','SS','LeNSE','CombHelperStudent','GNNpruner']:\n",
    "          try:\n",
    "            df_ = load_from_pickle(os.path.join(dataset_path,algorthim))\n",
    "\n",
    "            # columns =['Ground set(Pruned)','Ratio(%)','Queries(%)']\n",
    "            df['algorithm'].append(algorthim)\n",
    "            df['Ratio'].append(df_['Ratio(%)'].iloc[0])\n",
    "            df['Size of Ground Set'].append(df_['Pruned Ground set(%)'].iloc[0])\n",
    "            \n",
    "            # df['Objective Value(Unpruned)'].append(df_['Objective Value(Unpruned)'].iloc[0])\n",
    "            # df['Objective Value(Pruned)'].append(df_['Objective Value(Pruned)'].iloc[0])\n",
    "            # df['Queries'].append(df_['Queries(%)'].iloc[0].zfill(4))\n",
    "            # df['Queries'].append(df_['Queries(%)'].iloc[0])\n",
    "          except:\n",
    "            pass\n",
    "      # print(df)\n",
    "        df = pd.DataFrame(df)\n",
    "        # df['Queries'] = df['Queries'].apply(lambda x: f\"{x:.4f}\")\n",
    "        df['Size of Ground Set']=df['Size of Ground Set'].round(4)\n",
    "        # df['Queries'] = df['Queries'].round(4)\n",
    "        print(df)\n",
    "        print('-'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for problem in [\n",
    "                # 'MaxCover',\n",
    "                # 'MaxCut',\n",
    "                'IM'\n",
    "              ]:\n",
    "    root_folder=os.path.join(problem,'data')\n",
    "    # datasets=['Facebook','DBLP','Skitter','YouTube']\n",
    "    \n",
    "    datasets=os.listdir(root_folder)\n",
    "    print(datasets)\n",
    "    df = defaultdict(list)\n",
    "    for dataset in datasets:\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        # print('*'*20)\n",
    "        # print(dataset)\n",
    "        dataset_path = os.path.join(root_folder,dataset)\n",
    "        algorthims = os.listdir(dataset_path)\n",
    "\n",
    "        # df ={'algorithm':[],'Size of Ground Set':[],'Ratio':[],'Queries':[]}\n",
    "        \n",
    "        # for algorthim in ['Quickfilter','SS','LeNSE','CombHelperTeacher','CombHelperStudent','GNNpruner']:\n",
    "        for algorthim in ['SS','Quickfilter']:\n",
    "          try:\n",
    "            df_ = load_from_pickle(os.path.join(dataset_path,algorthim))\n",
    "            df['algorithm'].append(algorthim)\n",
    "            df['dataset'].append(dataset)\n",
    "            df['QueriesToPrune'].append(df_['QueriesToPrune'].iloc[0])\n",
    "\n",
    "\n",
    "          except:\n",
    "            pass\n",
    "    df = pd.DataFrame(df)\n",
    "    # df['Queries'] = df['Queries'].apply(lambda x: f\"{x:.4f}\")\n",
    "    # df['Size of Ground Set']=df['Size of Ground Set'].round(4) \n",
    "    # df['Queries'] = df['Queries'].round(4)\n",
    "    print(df)\n",
    "    # print('-'*20)\n",
    "\n",
    "# Pivot the dataframe to have 'SS' and 'Quickfilter' as columns\n",
    "df_pivot = df.pivot(index='dataset', columns='algorithm', values='QueriesToPrune')\n",
    "\n",
    "# Calculate the ratio of Quickfilter/SS\n",
    "df_pivot['Ratio'] =  df_pivot['SS']/df_pivot['Quickfilter'] \n",
    "\n",
    "# Reset the index for plotting\n",
    "df_pivot.reset_index(inplace=True)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming df_pivot is already defined\n",
    "plt.figure(dpi=300, figsize=(10, 8))\n",
    "ax = sns.barplot(x='dataset', y='Ratio', data=df_pivot, palette=sns.color_palette(\"Spectral\"))\n",
    "\n",
    "# Set a single hatch pattern (e.g., '/' or 'x') for all bars\n",
    "hatch = '/'  # Change this to any desired hatch pattern\n",
    "edge_color = 'black'  # Color for the edges\n",
    "\n",
    "# Apply the same hatch and edge color to each bar\n",
    "for bar in ax.patches:\n",
    "    bar.set_hatch(hatch)\n",
    "    bar.set_edgecolor(edge_color)  # Set the edge color\n",
    "    bar.set_linewidth(1.5)  # Optional: Set the linewidth of the edges\n",
    "\n",
    "# Adding the value labels on top of the bars\n",
    "for bar in ax.patches:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        yval,  # Position the text at the height of the bar\n",
    "        f'{yval:.2f}',  # Format the value to 2 decimal places\n",
    "        ha='center',  # Center the text horizontally\n",
    "        va='bottom',  # Position the text just above the bar\n",
    "        fontsize=16,  # Optional: Font size for the labels\n",
    "        color='black'  # Optional: Color for the labels\n",
    "    )\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Number of Oracle calls (Quickfilter/SS)', fontsize=20)\n",
    "plt.xticks(rotation=45, fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "# Adjust the layout and remove the top and right spines\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig(f'{problem}.pdf', bbox_inches='tight', dpi=300)\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Budget vs Single Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IM/data/Slashdot\n",
      "Data has been loaded from IM/data/Slashdot/knapsack_multi/Quickfilter_degree\n",
      "IM/data/YouTube\n",
      "Data has been loaded from IM/data/YouTube/knapsack_multi/Quickfilter_degree\n",
      "IM/data/web-Google\n",
      "IM/data/Deezer\n",
      "Data has been loaded from IM/data/Deezer/knapsack_multi/Quickfilter_degree\n",
      "IM/data/DBLP\n",
      "Data has been loaded from IM/data/DBLP/knapsack_multi/Quickfilter_degree\n",
      "IM/data/Facebook\n",
      "Data has been loaded from IM/data/Facebook/knapsack_multi/Quickfilter_degree\n",
      "IM/data/Twitter\n",
      "Data has been loaded from IM/data/Twitter/knapsack_multi/Quickfilter_degree\n",
      "IM/data/Wiki\n",
      "Data has been loaded from IM/data/Wiki/knapsack_multi/Quickfilter_degree\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "for problem in [\n",
    "                # 'MaxCover',\n",
    "                # 'MaxCut',\n",
    "                'IM'\n",
    "              ]:\n",
    "    image_folder = f'{problem}/figures'\n",
    "    os.makedirs(image_folder,exist_ok=True)\n",
    "    root_folder=os.path.join(problem,'data')\n",
    "    # datasets=['Facebook','DBLP','Skitter','YouTube']\n",
    "    for folder in [\n",
    "                    # 'knapsack',\n",
    "                    'knapsack_multi'\n",
    "                    ]:\n",
    "        datasets=os.listdir(root_folder)\n",
    "\n",
    "        \n",
    "        # df ={'algorithm':[],'Size of Ground Set':[],'Ratio':[],'Queries':[]}\n",
    "        df =defaultdict(list)\n",
    "\n",
    "        for dataset in datasets:\n",
    "\n",
    "            # print('*'*20)\n",
    "            # print(dataset)\n",
    "            dataset_path = os.path.join(root_folder,dataset)\n",
    "            print(dataset_path)\n",
    "            try:\n",
    "                # print(os.path.join(dataset_path,folder,'Quickfilter_degree'))\n",
    "                # df_ = load_from_pickle(os.path.join(dataset_path,folder,'GNNpruner'))\n",
    "                df_ = load_from_pickle(os.path.join(dataset_path,folder,'Quickfilter_degree'))\n",
    "                \n",
    "                df_['Budget'] = [10,30,50,70,90,100]\n",
    "                # print(,folder,df_['Dataset'].iloc[0])\n",
    "                # df['dataset'].append(dataset)\n",
    "                # # df['algorithm'].append('QS')\n",
    "                # # df['Delta'].append(df_['Delta'].iloc[0])\n",
    "                # df['Size of Ground Set'].append(df_['Pruned Ground set(%)'].iloc[0])\n",
    "                \n",
    "                # df['Ratio'].append(df_['Ratio(%)'].iloc[0])\n",
    "                # # df['Queries'].append(df_['Queries(%)'].iloc[0])\n",
    "                plt.figure(dpi=200, figsize=(8,6))\n",
    "\n",
    "                # Scatter for Multi-Budget\n",
    "                plt.scatter(df_['Budget'], df_['Ratio Multi'], marker='o', s=200, color='blue', alpha=0.7)\n",
    "                plt.plot(df_['Budget'], df_['Ratio Multi'], linestyle='--', color='blue', \n",
    "                        label=f\"Multi-Budget $(P_g={df_['Pruned Ground set Multi(%)'].iloc[0]:.2f}\\%)$\")\n",
    "\n",
    "                # Scatter for Single-Budget\n",
    "                plt.scatter(df_['Budget'], df_['Ratio Single'], marker='*', s=300, color='red', alpha=0.7)\n",
    "                plt.plot(df_['Budget'], df_['Ratio Single'], linestyle='--',color='red', \n",
    "                        label=f\"Single-Budget $(P_g ={df_['Pruned Ground set Single(%)'].iloc[0]:.2f}\\%)$\")\n",
    "\n",
    "\n",
    "                fontsize = 30\n",
    "                # Adding grid, legend, and style\n",
    "                plt.grid(alpha=0.3, linestyle='--')\n",
    "                sns.despine()\n",
    "                plt.legend(frameon = False,fontsize = fontsize-6)\n",
    "                plt.title(df_['Dataset'].iloc[0],fontsize = fontsize)\n",
    "                plt.xlabel('Budgets', fontsize=fontsize )\n",
    "                plt.ylabel('Ratio (%)', fontsize=fontsize)\n",
    "                plt.xticks(fontsize=fontsize )\n",
    "                plt.yticks(fontsize=fontsize )\n",
    "                plt.locator_params(nbins=6)\n",
    "                \n",
    "                file_name = os.path.join(image_folder,df_['Dataset'].iloc[0])\n",
    "                \n",
    "                # plt.savefig(f'{file_name}', bbox_inches='tight')\n",
    "                plt.savefig(f'{file_name}.pdf', bbox_inches='tight',dpi=300)\n",
    "\n",
    "                plt.close()\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        # # print(df)\n",
    "        # df = pd.DataFrame(df)\n",
    "        # print(df)\n",
    "        # # print('-'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (6) does not match length of index (5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBudget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m30\u001b[39m,\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m70\u001b[39m,\u001b[38;5;241m90\u001b[39m,\u001b[38;5;241m100\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/eco_dqn/lib/python3.10/site-packages/pandas/core/frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3979\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/eco_dqn/lib/python3.10/site-packages/pandas/core/frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4166\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4167\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4172\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4174\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4177\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4178\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4179\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4180\u001b[0m     ):\n\u001b[1;32m   4181\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/anaconda3/envs/eco_dqn/lib/python3.10/site-packages/pandas/core/frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4915\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/eco_dqn/lib/python3.10/site-packages/pandas/core/common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (6) does not match length of index (5)"
     ]
    }
   ],
   "source": [
    "df_['Budget'] = [10,30,50,70,90,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Objective Value(Unpruned)</th>\n",
       "      <th>Objective Value Multi(Pruned)</th>\n",
       "      <th>Objective Value Single(Pruned)</th>\n",
       "      <th>Ground Set</th>\n",
       "      <th>Ground set Multi (Pruned)</th>\n",
       "      <th>Ground set Single (Pruned)</th>\n",
       "      <th>Time(Unpruned)</th>\n",
       "      <th>...</th>\n",
       "      <th>Pruned Ground set Multi(%)</th>\n",
       "      <th>Pruned Ground set Single(%)</th>\n",
       "      <th>Ratio Multi</th>\n",
       "      <th>Ratio Single</th>\n",
       "      <th>Queries Multi(%)</th>\n",
       "      <th>Queries Single(%)</th>\n",
       "      <th>TimeRatio(Multi)</th>\n",
       "      <th>TimeRatio(Single)</th>\n",
       "      <th>TimeToPrune(Multi)</th>\n",
       "      <th>TimeToPrune(Single)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wiki</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>501.9568</td>\n",
       "      <td>500.5362</td>\n",
       "      <td>501.6191</td>\n",
       "      <td>7115</td>\n",
       "      <td>1493</td>\n",
       "      <td>1103</td>\n",
       "      <td>34.422188</td>\n",
       "      <td>...</td>\n",
       "      <td>20.98</td>\n",
       "      <td>15.5</td>\n",
       "      <td>99.72</td>\n",
       "      <td>99.93</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.942341</td>\n",
       "      <td>0.946726</td>\n",
       "      <td>4.661208</td>\n",
       "      <td>0.32427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wiki</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>532.2225</td>\n",
       "      <td>530.9716</td>\n",
       "      <td>534.2960</td>\n",
       "      <td>7115</td>\n",
       "      <td>1493</td>\n",
       "      <td>1103</td>\n",
       "      <td>36.122127</td>\n",
       "      <td>...</td>\n",
       "      <td>20.98</td>\n",
       "      <td>15.5</td>\n",
       "      <td>99.76</td>\n",
       "      <td>100.39</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.945139</td>\n",
       "      <td>0.946864</td>\n",
       "      <td>4.661208</td>\n",
       "      <td>0.32427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wiki</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>578.5566</td>\n",
       "      <td>574.1263</td>\n",
       "      <td>578.0386</td>\n",
       "      <td>7115</td>\n",
       "      <td>1493</td>\n",
       "      <td>1103</td>\n",
       "      <td>38.443724</td>\n",
       "      <td>...</td>\n",
       "      <td>20.98</td>\n",
       "      <td>15.5</td>\n",
       "      <td>99.23</td>\n",
       "      <td>99.91</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.938684</td>\n",
       "      <td>0.945277</td>\n",
       "      <td>4.661208</td>\n",
       "      <td>0.32427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wiki</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>648.0111</td>\n",
       "      <td>643.0056</td>\n",
       "      <td>648.1275</td>\n",
       "      <td>7115</td>\n",
       "      <td>1493</td>\n",
       "      <td>1103</td>\n",
       "      <td>41.528946</td>\n",
       "      <td>...</td>\n",
       "      <td>20.98</td>\n",
       "      <td>15.5</td>\n",
       "      <td>99.23</td>\n",
       "      <td>100.02</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.928828</td>\n",
       "      <td>0.946658</td>\n",
       "      <td>4.661208</td>\n",
       "      <td>0.32427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wiki</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>677.1219</td>\n",
       "      <td>670.1255</td>\n",
       "      <td>679.0261</td>\n",
       "      <td>7115</td>\n",
       "      <td>1493</td>\n",
       "      <td>1103</td>\n",
       "      <td>42.507277</td>\n",
       "      <td>...</td>\n",
       "      <td>20.98</td>\n",
       "      <td>15.5</td>\n",
       "      <td>98.97</td>\n",
       "      <td>100.28</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.929990</td>\n",
       "      <td>0.953630</td>\n",
       "      <td>4.661208</td>\n",
       "      <td>0.32427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Budget  Delta  Objective Value(Unpruned)  \\\n",
       "0    Wiki       4    0.1                   501.9568   \n",
       "1    Wiki       4    0.1                   532.2225   \n",
       "2    Wiki       4    0.1                   578.5566   \n",
       "3    Wiki       4    0.1                   648.0111   \n",
       "4    Wiki       4    0.1                   677.1219   \n",
       "\n",
       "   Objective Value Multi(Pruned)  Objective Value Single(Pruned)  Ground Set  \\\n",
       "0                       500.5362                        501.6191        7115   \n",
       "1                       530.9716                        534.2960        7115   \n",
       "2                       574.1263                        578.0386        7115   \n",
       "3                       643.0056                        648.1275        7115   \n",
       "4                       670.1255                        679.0261        7115   \n",
       "\n",
       "   Ground set Multi (Pruned)  Ground set Single (Pruned)  Time(Unpruned)  ...  \\\n",
       "0                       1493                        1103       34.422188  ...   \n",
       "1                       1493                        1103       36.122127  ...   \n",
       "2                       1493                        1103       38.443724  ...   \n",
       "3                       1493                        1103       41.528946  ...   \n",
       "4                       1493                        1103       42.507277  ...   \n",
       "\n",
       "   Pruned Ground set Multi(%)  Pruned Ground set Single(%)  Ratio Multi  \\\n",
       "0                       20.98                         15.5        99.72   \n",
       "1                       20.98                         15.5        99.76   \n",
       "2                       20.98                         15.5        99.23   \n",
       "3                       20.98                         15.5        99.23   \n",
       "4                       20.98                         15.5        98.97   \n",
       "\n",
       "   Ratio Single  Queries Multi(%)  Queries Single(%)  TimeRatio(Multi)  \\\n",
       "0         99.93              4.41               2.41          0.942341   \n",
       "1        100.39              4.41               2.41          0.945139   \n",
       "2         99.91              4.41               2.41          0.938684   \n",
       "3        100.02              4.41               2.41          0.928828   \n",
       "4        100.28              4.41               2.41          0.929990   \n",
       "\n",
       "   TimeRatio(Single)  TimeToPrune(Multi)  TimeToPrune(Single)  \n",
       "0           0.946726            4.661208              0.32427  \n",
       "1           0.946864            4.661208              0.32427  \n",
       "2           0.945277            4.661208              0.32427  \n",
       "3           0.946658            4.661208              0.32427  \n",
       "4           0.953630            4.661208              0.32427  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxCover/data/Slashdot\n",
      "Data has been loaded from MaxCover/data/Slashdot/Knapsack_GNN/GNNpruner\n",
      "Knapsack_GNN Slashdot\n",
      "MaxCover/data/YouTube\n",
      "MaxCover/data/Deezer\n",
      "Data has been loaded from MaxCover/data/Deezer/Knapsack_GNN/GNNpruner\n",
      "Knapsack_GNN Deezer\n",
      "MaxCover/data/Skitter\n",
      "Data has been loaded from MaxCover/data/Skitter/Knapsack_GNN/GNNpruner\n",
      "Knapsack_GNN Skitter\n",
      "MaxCover/data/DBLP\n",
      "MaxCover/data/Facebook\n",
      "Data has been loaded from MaxCover/data/Facebook/Knapsack_GNN/GNNpruner\n",
      "Knapsack_GNN Facebook\n",
      "MaxCover/data/Twitter\n",
      "Data has been loaded from MaxCover/data/Twitter/Knapsack_GNN/GNNpruner\n",
      "Knapsack_GNN Twitter\n",
      "MaxCover/data/Wiki\n",
      "Data has been loaded from MaxCover/data/Wiki/Knapsack_GNN/GNNpruner\n",
      "Knapsack_GNN Wiki\n",
      "    dataset  Pruned Ground set(%)  Ratio\n",
      "0  Slashdot                 56.47  76.45\n",
      "1    Deezer                 24.26  66.21\n",
      "2   Skitter                 45.96  58.15\n",
      "3  Facebook                 22.16  34.24\n",
      "4   Twitter                  1.82   2.32\n",
      "5      Wiki                 48.10  73.09\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "for problem in [\n",
    "                'MaxCover',\n",
    "                # 'MaxCut'\n",
    "              ]:\n",
    "    image_folder = f'{problem}/figures'\n",
    "    os.makedirs(image_folder,exist_ok=True)\n",
    "    root_folder=os.path.join(problem,'data')\n",
    "    \n",
    "    for folder in [\n",
    "                    # 'knapsack',\n",
    "                    'Knapsack_GNN'\n",
    "                    ]:\n",
    "        datasets=os.listdir(root_folder)\n",
    "\n",
    "        \n",
    "        # df ={'algorithm':[],'Size of Ground Set':[],'Ratio':[],'Queries':[]}\n",
    "        df =defaultdict(list)\n",
    "\n",
    "        for dataset in datasets:\n",
    "\n",
    "            # print('*'*20)\n",
    "            # print(dataset)\n",
    "            dataset_path = os.path.join(root_folder,dataset)\n",
    "            print(dataset_path)\n",
    "            try:\n",
    "                # print(os.path.join(dataset_path,folder,'Quickfilter_degree'))\n",
    "                df_ = load_from_pickle(os.path.join(dataset_path,folder,'GNNpruner'))\n",
    "                # df_ = load_from_pickle(os.path.join(dataset_path,folder,'Quickfilter_degree'))\n",
    "                print(folder,df_['Dataset'].iloc[0])\n",
    "                df['dataset'].append(dataset)\n",
    "                df['Pruned Ground set(%)'].append(df_['Pruned Ground set(%)'].iloc[0])\n",
    "                df['Ratio'].append(df_['Ratio(%)'].iloc[0])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "print(df)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Objective Value(Unpruned)</th>\n",
       "      <th>Objective Value(Pruned)</th>\n",
       "      <th>Ground Set</th>\n",
       "      <th>Ground set(Pruned)</th>\n",
       "      <th>Queries(Unpruned)</th>\n",
       "      <th>Time(Unpruned)</th>\n",
       "      <th>Time(Pruned)</th>\n",
       "      <th>Queries(Pruned)</th>\n",
       "      <th>Pruned Ground set(%)</th>\n",
       "      <th>Ratio(%)</th>\n",
       "      <th>Queries(%)</th>\n",
       "      <th>TimeRatio</th>\n",
       "      <th>TimeToPrune</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wiki</td>\n",
       "      <td>100</td>\n",
       "      <td>7115</td>\n",
       "      <td>5200</td>\n",
       "      <td>7115</td>\n",
       "      <td>3422</td>\n",
       "      <td>25322285</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>5860175</td>\n",
       "      <td>48.1</td>\n",
       "      <td>73.09</td>\n",
       "      <td>23.14</td>\n",
       "      <td>0.831469</td>\n",
       "      <td>0.015541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Budget  Objective Value(Unpruned)  Objective Value(Pruned)  \\\n",
       "0    Wiki     100                       7115                     5200   \n",
       "\n",
       "   Ground Set  Ground set(Pruned)  Queries(Unpruned)  Time(Unpruned)  \\\n",
       "0        7115                3422           25322285           0.143   \n",
       "\n",
       "   Time(Pruned)  Queries(Pruned)  Pruned Ground set(%)  Ratio(%)  Queries(%)  \\\n",
       "0        0.1189          5860175                  48.1     73.09       23.14   \n",
       "\n",
       "   TimeRatio  TimeToPrune  \n",
       "0   0.831469     0.015541  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ground_set = {\n",
    "    'Facebook': 3398,\n",
    "    'Wiki': 6349,\n",
    "    'Deezer': 53555,\n",
    "    'Slashdot':67677,\n",
    "    'Twitter': 80779,\n",
    "    'DBLP':314818,\n",
    "    'YouTube':1094439,\n",
    "    'Skitter': 1694024\n",
    "\n",
    "}\n",
    "\n",
    "data_MVC_Lense = {\n",
    "    'Facebook': 300,\n",
    "    'Wiki': 300,\n",
    "    'Deezer': 500,\n",
    "    'Slashdot': 500,\n",
    "    'Twitter': 1000,\n",
    "    'DBLP': 1000,\n",
    "    'YouTube': 1250,\n",
    "    'Skitter': 750\n",
    "}\n",
    "\n",
    "data_IM_Lense = {\n",
    "    'Facebook': 300,\n",
    "    'Wiki': 300,\n",
    "    'Deezer': 500,\n",
    "    'Slashdot': 500,\n",
    "    'Twitter': 1000,\n",
    "    'DBLP': 1000,\n",
    "    'YouTube': 750,\n",
    "    'Skitter': 750\n",
    "}\n",
    "\n",
    "\n",
    "for key in data_MVC_Lense:\n",
    "    print(key,data_MVC_Lense[key]/Ground_set[key])\n",
    "\n",
    "\n",
    "for key in data_MVC_Lense:\n",
    "    print(key,data_MVC_Lense[key]/Ground_set[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for problem in [\n",
    "                'MaxCover',\n",
    "\n",
    "              ]:\n",
    "    root_folder=os.path.join(problem,'data')\n",
    "    \n",
    "    \n",
    "    datasets=os.listdir(root_folder)\n",
    "    # print(datasets)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        \n",
    "        print('*'*20)\n",
    "        print(dataset)\n",
    "        dataset_path = os.path.join(root_folder,dataset)\n",
    "        algorthims = os.listdir(dataset_path)\n",
    "\n",
    "        # df ={'algorithm':[],'Size of Ground Set':[],'Ratio':[],'Queries':[]}\n",
    "        df = defaultdict(list)\n",
    "        # for algorthim in ['Quickfilter','SS','LeNSE','CombHelperTeacher','CombHelperStudent','GNNpruner']:\n",
    "        for algorthim in ['Quickfilter','SS','LeNSE','CombHelperStudent','GNNpruner']:\n",
    "          try:\n",
    "            df_ = load_from_pickle(os.path.join(dataset_path,algorthim))\n",
    "\n",
    "            # columns =['Ground set(Pruned)','Ratio(%)','Queries(%)']\n",
    "            df['algorithm'].append(algorthim)\n",
    "            df['Size of Ground Set'].append(df_['Pruned Ground set(%)'].iloc[0])\n",
    "            df['Ratio'].append(df_['Ratio(%)'].iloc[0])\n",
    "            # df['Objective Value(Unpruned)'].append(df_['Objective Value(Unpruned)'].iloc[0])\n",
    "            # df['Objective Value(Pruned)'].append(df_['Objective Value(Pruned)'].iloc[0])\n",
    "            # df['Queries'].append(df_['Queries(%)'].iloc[0].zfill(4))\n",
    "            # df['Queries'].append(df_['Queries(%)'].iloc[0])\n",
    "          except:\n",
    "            pass\n",
    "      # print(df)\n",
    "        df = pd.DataFrame(df)\n",
    "        # df['Queries'] = df['Queries'].apply(lambda x: f\"{x:.4f}\")\n",
    "        df['Size of Ground Set']=df['Size of Ground Set'].round(4)\n",
    "        # df['Queries'] = df['Queries'].round(4)\n",
    "        print(df)\n",
    "        print('-'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
