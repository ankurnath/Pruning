{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections  import defaultdict\n",
    "import pickle\n",
    "import pandas as pd\n",
    "def load_from_pickle(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a pickle file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: The path to the pickle file.\n",
    "\n",
    "    Returns:\n",
    "    - loaded_data: The loaded data.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        loaded_data = pickle.load(file)\n",
    "    # print(f'Data has been loaded from {file_path}')\n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Facebook', 'Wiki']\n",
      "********************\n",
      "Facebook\n",
      "     algorithm  Size of Ground Set   Ratio\n",
      "0  Quickfilter               23.20   98.66\n",
      "1           SS                9.73   94.36\n",
      "2        GCOMB               59.54  100.40\n",
      "--------------------\n",
      "********************\n",
      "Wiki\n",
      "     algorithm  Size of Ground Set   Ratio\n",
      "0  Quickfilter               10.82  100.90\n",
      "1           SS                6.54   98.52\n",
      "2        GCOMB               28.35   99.73\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for problem in [\n",
    "                # 'MaxCover',\n",
    "                # 'MaxCut',\n",
    "                'IM'\n",
    "              ]:\n",
    "    root_folder=os.path.join(problem,'data')\n",
    "    # datasets=['Facebook','DBLP','Skitter','YouTube']\n",
    "    \n",
    "    datasets=os.listdir(root_folder)\n",
    "    print(datasets)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        print('*'*20)\n",
    "        print(dataset)\n",
    "        dataset_path = os.path.join(root_folder,dataset)\n",
    "        algorthims = os.listdir(dataset_path)\n",
    "\n",
    "        # df ={'algorithm':[],'Size of Ground Set':[],'Ratio':[],'Queries':[]}\n",
    "        df = defaultdict(list)\n",
    "        for algorthim in ['Quickfilter','SS','GCOMB','LeNSE','CombHelperTeacher','CombHelperStudent','GNNpruner']:\n",
    "          try:\n",
    "            df_ = load_from_pickle(os.path.join(dataset_path,algorthim))\n",
    "\n",
    "            # columns =['Ground set(Pruned)','Ratio(%)','Queries(%)']\n",
    "            df['algorithm'].append(algorthim)\n",
    "            df['Size of Ground Set'].append(df_['Pruned Ground set(%)'].iloc[0])\n",
    "            df['Ratio'].append(df_['Ratio(%)'].iloc[0])\n",
    "            # df['Queries'].append(df_['Queries(%)'].iloc[0])\n",
    "          except:\n",
    "            pass\n",
    "      # print(df)\n",
    "        df = pd.DataFrame(df)\n",
    "        print(df)\n",
    "        print('-'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      dataset algorithm  Delta  Size of Ground Set  Ratio  Queries\n",
      "0    Slashdot        QS    0.1               38.69  95.59    60.28\n",
      "1  web-Google        QS    0.1               25.32  95.11    79.14\n",
      "2        DBLP        QS    0.1               27.66  97.18    39.23\n",
      "3    Facebook        QS    0.1               48.06  95.16   977.84\n",
      "4     Twitter        QS    0.1               31.93  97.89   297.68\n",
      "5        Wiki        QS    0.1               27.98  94.87    52.83\n"
     ]
    }
   ],
   "source": [
    "for problem in [\n",
    "                # 'MaxCover',\n",
    "                'MaxCut'\n",
    "              ]:\n",
    "    root_folder=os.path.join(problem,'data')\n",
    "    # datasets=['Facebook','DBLP','Skitter','YouTube']\n",
    "    for folder in ['knapsack']:\n",
    "        datasets=os.listdir(root_folder)\n",
    "\n",
    "        \n",
    "        # df ={'algorithm':[],'Size of Ground Set':[],'Ratio':[],'Queries':[]}\n",
    "        df =defaultdict(list)\n",
    "\n",
    "        for dataset in datasets:\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            # print('*'*20)\n",
    "            # print(dataset)\n",
    "            dataset_path = os.path.join(root_folder,dataset)\n",
    "            try:\n",
    "                # print(os.path.join(dataset_path,folder,'Quickfilter_degree'))\n",
    "                df_ = load_from_pickle(os.path.join(dataset_path,folder,'Quickfilter_degree'))\n",
    "                df['dataset'].append(dataset)\n",
    "                df['algorithm'].append('QS')\n",
    "                df['Delta'].append(df_['Delta'].iloc[0])\n",
    "                df['Size of Ground Set'].append(df_['Pruned Ground set(%)'].iloc[0])\n",
    "                \n",
    "                df['Ratio'].append(df_['Ratio(%)'].iloc[0])\n",
    "                df['Queries'].append(df_['Queries(%)'].iloc[0])\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        # print(df)\n",
    "        df = pd.DataFrame(df)\n",
    "        print(df)\n",
    "        # print('-'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
