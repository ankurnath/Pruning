{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections  import defaultdict\n",
    "import pickle\n",
    "import pandas as pd\n",
    "def load_from_pickle(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a pickle file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: The path to the pickle file.\n",
    "\n",
    "    Returns:\n",
    "    - loaded_data: The loaded data.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        loaded_data = pickle.load(file)\n",
    "    # print(f'Data has been loaded from {file_path}')\n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Slashdot', 'YouTube', 'web-Google', 'Deezer', 'DBLP', 'Facebook', 'Twitter', 'Wiki']\n",
      "********************\n",
      "Slashdot\n",
      "           algorithm   Ratio  Queries\n",
      "0        Quickfilter   99.60     0.61\n",
      "1                 SS   99.59     1.04\n",
      "2  CombHelperStudent  100.76     1.19\n",
      "3          GNNpruner   99.93     1.96\n",
      "--------------------\n",
      "********************\n",
      "YouTube\n",
      "           algorithm   Ratio  Queries\n",
      "0        Quickfilter   99.98     0.01\n",
      "1                 SS   98.46     0.12\n",
      "2  CombHelperStudent   99.92     2.94\n",
      "3          GNNpruner  100.18     0.34\n",
      "--------------------\n",
      "********************\n",
      "web-Google\n",
      "           algorithm  Ratio  Queries\n",
      "0  CombHelperStudent  98.55     4.11\n",
      "--------------------\n",
      "********************\n",
      "Deezer\n",
      "           algorithm   Ratio  Queries\n",
      "0        Quickfilter   98.80     2.57\n",
      "1                 SS  102.62     1.36\n",
      "2  CombHelperStudent   98.37    89.06\n",
      "3          GNNpruner   99.84    15.14\n",
      "--------------------\n",
      "********************\n",
      "DBLP\n",
      "           algorithm   Ratio  Queries\n",
      "0        Quickfilter   89.42     0.53\n",
      "1                 SS  104.95     0.35\n",
      "2  CombHelperStudent   98.73    98.06\n",
      "3          GNNpruner   75.58    66.74\n",
      "--------------------\n",
      "********************\n",
      "Facebook\n",
      "           algorithm   Ratio  Queries\n",
      "0        Quickfilter   98.17    19.56\n",
      "1                 SS   92.08     8.61\n",
      "2  CombHelperStudent  100.39    67.11\n",
      "3          GNNpruner   99.38    50.22\n",
      "--------------------\n",
      "********************\n",
      "Twitter\n",
      "           algorithm   Ratio  Queries\n",
      "0        Quickfilter  100.40     0.08\n",
      "1                 SS   95.75     1.01\n",
      "2  CombHelperStudent   99.72    50.50\n",
      "3          GNNpruner   98.42     2.36\n",
      "--------------------\n",
      "********************\n",
      "Wiki\n",
      "           algorithm   Ratio  Queries\n",
      "0        Quickfilter  101.36     7.15\n",
      "1                 SS   98.63     5.88\n",
      "2  CombHelperStudent   99.69    38.91\n",
      "3          GNNpruner  100.11     9.73\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for problem in [\n",
    "                # 'MaxCover',\n",
    "                # 'MaxCut',\n",
    "                'IM'\n",
    "              ]:\n",
    "    root_folder=os.path.join(problem,'data')\n",
    "    # datasets=['Facebook','DBLP','Skitter','YouTube']\n",
    "    \n",
    "    datasets=os.listdir(root_folder)\n",
    "    print(datasets)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        print('*'*20)\n",
    "        print(dataset)\n",
    "        dataset_path = os.path.join(root_folder,dataset)\n",
    "        algorthims = os.listdir(dataset_path)\n",
    "\n",
    "        # df ={'algorithm':[],'Size of Ground Set':[],'Ratio':[],'Queries':[]}\n",
    "        df = defaultdict(list)\n",
    "        # for algorthim in ['Quickfilter','SS','LeNSE','CombHelperTeacher','CombHelperStudent','GNNpruner']:\n",
    "        for algorthim in ['Quickfilter','SS','LeNSE','CombHelperStudent','GNNpruner']:\n",
    "          try:\n",
    "            df_ = load_from_pickle(os.path.join(dataset_path,algorthim))\n",
    "\n",
    "            # columns =['Ground set(Pruned)','Ratio(%)','Queries(%)']\n",
    "            df['algorithm'].append(algorthim)\n",
    "            # df['Size of Ground Set'].append(df_['Pruned Ground set(%)'].iloc[0])\n",
    "            df['Ratio'].append(df_['Ratio(%)'].iloc[0])\n",
    "            # df['Objective Value(Unpruned)'].append(df_['Objective Value(Unpruned)'].iloc[0])\n",
    "            # df['Objective Value(Pruned)'].append(df_['Objective Value(Pruned)'].iloc[0])\n",
    "            # df['Queries'].append(df_['Queries(%)'].iloc[0].zfill(4))\n",
    "            df['Queries'].append(df_['Queries(%)'].iloc[0])\n",
    "          except:\n",
    "            pass\n",
    "      # print(df)\n",
    "        df = pd.DataFrame(df)\n",
    "        # df['Queries'] = df['Queries'].apply(lambda x: f\"{x:.4f}\")\n",
    "        df['Queries'] = df['Queries'].round(4)\n",
    "        print(df)\n",
    "        print('-'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      dataset  Size of Ground Set   Ratio\n",
      "0    Slashdot               21.73   86.89\n",
      "1     YouTube               22.53   98.60\n",
      "2  web-Google               13.40   77.94\n",
      "3     Skitter               18.06   97.68\n",
      "4        DBLP               22.81   69.99\n",
      "5    Facebook                0.50  100.00\n",
      "6     Twitter                8.92   99.99\n",
      "7        Wiki               19.14  100.00\n"
     ]
    }
   ],
   "source": [
    "for problem in [\n",
    "                'MaxCover',\n",
    "                # 'MaxCut'\n",
    "              ]:\n",
    "    root_folder=os.path.join(problem,'data')\n",
    "    # datasets=['Facebook','DBLP','Skitter','YouTube']\n",
    "    for folder in [\n",
    "                    'knapsack',\n",
    "                    # 'Knapsack_GNN'\n",
    "                    ]:\n",
    "        datasets=os.listdir(root_folder)\n",
    "\n",
    "        \n",
    "        # df ={'algorithm':[],'Size of Ground Set':[],'Ratio':[],'Queries':[]}\n",
    "        df =defaultdict(list)\n",
    "\n",
    "        for dataset in datasets:\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            # print('*'*20)\n",
    "            # print(dataset)\n",
    "            dataset_path = os.path.join(root_folder,dataset)\n",
    "            try:\n",
    "                # print(os.path.join(dataset_path,folder,'Quickfilter_degree'))\n",
    "                # df_ = load_from_pickle(os.path.join(dataset_path,folder,'GNNpruner'))\n",
    "                df_ = load_from_pickle(os.path.join(dataset_path,folder,'Quickfilter_degree'))\n",
    "                df['dataset'].append(dataset)\n",
    "                # df['algorithm'].append('QS')\n",
    "                # df['Delta'].append(df_['Delta'].iloc[0])\n",
    "                df['Size of Ground Set'].append(df_['Pruned Ground set(%)'].iloc[0])\n",
    "                \n",
    "                df['Ratio'].append(df_['Ratio(%)'].iloc[0])\n",
    "                # df['Queries'].append(df_['Queries(%)'].iloc[0])\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        # print(df)\n",
    "        df = pd.DataFrame(df)\n",
    "        print(df)\n",
    "        # print('-'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'dataset': ['Facebook', 'Twitter', 'Wiki'],\n",
       "             'algorithm': ['QS', 'QS', 'QS'],\n",
       "             'Delta': []})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
